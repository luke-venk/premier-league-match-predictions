{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0465664e-0d2f-4582-8500-86eb0c42ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/code/premier-league-match-predictions'\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import lightgbm as lgb\n",
    "\n",
    "from src.config import Models\n",
    "from src.config import END_YEAR, NUM_SEASONS, SPORTSBOOK, N_MATCHES\n",
    "from src.data.load_data import load_all_seasons\n",
    "from src.data.build_features import build_rolling_features\n",
    "from src.data.split import chrono_split\n",
    "from src.models.hyperparameter_search import search_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e184444-dfa5-492f-bb23-8dbf66782303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_all_seasons(end_year=END_YEAR, num_seasons=NUM_SEASONS, sportsbook=SPORTSBOOK)\n",
    "df = build_rolling_features(df=df_raw, n_matches=N_MATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e46c8c0-8eaf-4397-af1f-c46dcc03203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = chrono_split(df, train_ratio=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a130f0-8d23-45ae-a7bf-32076fb5a301",
   "metadata": {},
   "source": [
    "### Parameter Grid to Search\n",
    "Here you should define the parameter grid for each of the models, so the program can search the best hyperparameters for each model. Use this program to determine the optimal hyperparameters to use for a given dataset, and update the src/ directory accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e1ba9f-397b-4f7c-93fb-a09f5d328fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "\n",
    "    Models.NAIVE_BAYES: {\n",
    "        \"model\": Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"clf\", GaussianNB(var_smoothing=1e-9))\n",
    "        ]),\n",
    "        \"params\": {\n",
    "            \"clf__var_smoothing\": [1e-9, 1e-8, 1e-7]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    Models.LOGISTIC_REGRESSION: {\n",
    "        \"model\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=5000\n",
    "            ))\n",
    "        ]),\n",
    "        \"params\": {\n",
    "            \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "            \"clf__penalty\": [\"l2\"],\n",
    "            \"clf__solver\": [\"lbfgs\"]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    Models.RANDOM_FOREST: {\n",
    "        \"model\": Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"clf\", RandomForestClassifier(\n",
    "                n_estimators=600,\n",
    "                max_depth=None,\n",
    "                min_samples_leaf=2,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=0\n",
    "            ))\n",
    "        ]),\n",
    "        \"params\": {\n",
    "            \"clf__n_estimators\": [300, 600, 900],\n",
    "            \"clf__max_depth\": [None, 10, 20],\n",
    "            \"clf__min_samples_leaf\": [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    Models.SVM: {\n",
    "        \"model\": Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(\n",
    "                kernel=\"rbf\",\n",
    "                C=2.0,\n",
    "                gamma=\"scale\",\n",
    "                probability=True,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=0\n",
    "            ))\n",
    "        ]),\n",
    "        \"params\": {\n",
    "            \"clf__C\": [0.5, 1.0, 2.0, 4.0],\n",
    "            \"clf__kernel\": [\"rbf\", \"linear\"],\n",
    "            \"clf__gamma\": [\"scale\", \"auto\"]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    Models.MLPFFNN: {\n",
    "        \"model\": Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", MLPClassifier(\n",
    "                hidden_layer_sizes=(64, 32),\n",
    "                activation=\"relu\",\n",
    "                solver=\"adam\",\n",
    "                alpha=1e-3,\n",
    "                learning_rate_init=1e-2,\n",
    "                max_iter=5000,\n",
    "                random_state=0\n",
    "            ))\n",
    "        ]),\n",
    "        \"params\": {\n",
    "            \"clf__hidden_layer_sizes\": [(64,32), (128,64), (128,64,32)],\n",
    "            \"clf__alpha\": [1e-4, 1e-3, 1e-2],\n",
    "            \"clf__learning_rate_init\": [1e-3, 1e-2],\n",
    "            \"clf__activation\": [\"relu\", \"tanh\"]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    Models.LIGHTGBM: {\n",
    "        \"model\": Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"clf\", lgb.LGBMClassifier(\n",
    "                objective=\"multiclass\",\n",
    "                num_class=3,\n",
    "                n_estimators=600,\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=30,\n",
    "                subsample=0.9,\n",
    "                colsample_bytree=0.9,\n",
    "                reg_lambda=1.0,\n",
    "                random_state=0\n",
    "            ))\n",
    "        ]),\n",
    "        \"params\": {\n",
    "            \"clf__n_estimators\": [300, 600, 900],\n",
    "            \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"clf__num_leaves\": [20, 30, 40],\n",
    "            \"clf__subsample\": [0.8, 0.9, 1.0],\n",
    "            \"clf__colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "            \"clf__reg_lambda\": [0.5, 1.0, 2.0]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    Models.XGBOOST: {\n",
    "        \"model\": Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"clf\", XGBClassifier(\n",
    "                objective=\"multi:softprob\",\n",
    "                num_class=3,\n",
    "                n_estimators=600,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.9,\n",
    "                colsample_bytree=0.9,\n",
    "                reg_lambda=1.0,\n",
    "                tree_method=\"hist\",\n",
    "                eval_metric=\"mlogloss\",\n",
    "                random_state=0\n",
    "            ))\n",
    "        ]),\n",
    "        \"params\": {\n",
    "            \"clf__n_estimators\": [300, 600, 900],\n",
    "            \"clf__max_depth\": [3, 4, 5],\n",
    "            \"clf__learning_rate\": [0.05, 0.1],\n",
    "            \"clf__subsample\": [0.9, 1.0],\n",
    "            \"clf__colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "            \"clf__reg_lambda\": [0.5, 1.0, 2.0]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583244f-3683-48af-8594-674eb7816b7a",
   "metadata": {},
   "source": [
    "### Running the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f982ea-7912-425f-83ab-c9e08fc9fa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Models.NAIVE_BAYES...\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Finished tuning Models.NAIVE_BAYES in 1.44 seconds.\n",
      "Best score = 0.46613249699261045.\n",
      "Best params = {'clf__var_smoothing': 1e-09}\n",
      "\n",
      "\n",
      "Tuning Models.LOGISTIC_REGRESSION...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Finished tuning Models.LOGISTIC_REGRESSION in 0.24 seconds.\n",
      "Best score = 0.5512545110843787.\n",
      "Best params = {'clf__C': 0.01, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n",
      "\n",
      "\n",
      "Tuning Models.RANDOM_FOREST...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "grid_searches = search_models(param_grids, X_train, y_train)\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': grid_search['name'],\n",
    "        'Best Accuracy': grid_search['best_score'],\n",
    "        'Best Params': grid_search['best_params']\n",
    "    }\n",
    "    for grid_search in grid_searches\n",
    "])\n",
    "\n",
    "summary_df.sort_values('Best Accuracy', ascending=False)\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
